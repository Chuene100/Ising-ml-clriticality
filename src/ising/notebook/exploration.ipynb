{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da3280d",
   "metadata": {},
   "source": [
    "# Ising Model ML Exploration\n",
    "\n",
    "This notebook demonstrates how to load Ising model data, train a VDNN model, and evaluate its performance using the modular codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09646d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ising.training.train_dnn import train_dnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9b0b7e",
   "metadata": {},
   "source": [
    "## Load and Prepare Ising Dataset\n",
    "\n",
    "Load the Ising dataset, split into training and test sets, and preprocess as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c0c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Replace with actual data loading from ising.data.data_loader\n",
    "# For demonstration, generate random data\n",
    "n_samples = 1000\n",
    "n_features = 40*40\n",
    "X = np.random.rand(n_samples, n_features)\n",
    "y = np.random.randint(0, 2, size=(n_samples, 1))\n",
    "\n",
    "# Split into train and test sets\n",
    "split = int(0.8 * n_samples)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ae663",
   "metadata": {},
   "source": [
    "## Train VDNN Model\n",
    "\n",
    "Train the VDNN model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f06b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the VDNN model\n",
    "model, losses = train_dnn(X_train, y_train, depth=4, epochs=10, lr=1e-3, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a6d93",
   "metadata": {},
   "source": [
    "## Plot Training Loss Curve\n",
    "\n",
    "Visualize the training loss over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(losses, marker='o')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e332a",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "\n",
    "Use the trained model to make predictions on the test set and compute accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636397a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_pred = model(X_test_tensor).cpu().numpy()\n",
    "    y_pred_label = (y_pred > 0.5).astype(int)\n",
    "    accuracy = np.mean(y_pred_label == y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ising.plotting.plotting import plot_adversarial_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4671f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for G=0\n",
    "# plot_adversarial_results(df_adversarial_G_0, df_ordinary_G_0, G_0_adversarial_scatter_plot_info_dict, G_label='0')\n",
    "\n",
    "# Example usage for G=0.1\n",
    "# plot_adversarial_results(df_adversarial_G_0_1, df_ordinary_G_0_1, G_0_1_adversarial_scatter_plot_info_dict, G_label='0_1')\n",
    "\n",
    "# Example usage for G=0.5\n",
    "# plot_adversarial_results(df_adversarial_G_0_5, df_ordinary_G_0_5, G_0_5_adversarial_scatter_plot_info_dict, G_label='0_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fddc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "# Example: Load G0_data.h5py from src/ising/data\n",
    "h5_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'G0_data.h5py')\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    # Example: load dataset 'Ts' and print shape\n",
    "    Ts = f['Ts'][:]\n",
    "    print('Loaded Ts shape:', Ts.shape)\n",
    "    # Add more data loading as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63896562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from src/ising/data\n",
    "base_data_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data')\n",
    "f5 = h5py.File(os.path.join(base_data_path, 'G0_data.h5py'), 'r')\n",
    "f5_new = h5py.File(os.path.join(base_data_path, 'Gp1_data.h5py'), 'r')\n",
    "f5_new_2 = h5py.File(os.path.join(base_data_path, 'Gp5_data.h5py'), 'r')\n",
    "f5_new_3 = h5py.File(os.path.join(base_data_path, 'G1_J1_data.h5py'), 'r')\n",
    "f5_new_4 = h5py.File(os.path.join(base_data_path, 'G1_Jp01_data.h5py'), 'r')\n",
    "\n",
    "Ts_G_0 = f5['Ts'][:]\n",
    "Targs = np.arange(61)\n",
    "Targs_new = np.arange(80)\n",
    "xiBs = f5['xiBs'][:]\n",
    "factor = 0.30\n",
    "cut = np.amax(xiBs) * factor\n",
    "labels_tmp = np.heaviside(xiBs[Targs] - cut, 1.0)\n",
    "T0, T1 = Ts_G_0[np.where(labels_tmp == 1.0)[0][[0, -1]]]\n",
    "\n",
    "# Visualize labels\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(Ts_G_0[8:-9], labels_tmp[8:-9], '.-')\n",
    "plt.xticks(Ts_G_0[8:-9], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Prepare training and validation data\n",
    "data_train = f5['arrs'][Targs, :8000, :]\n",
    "data_validate = f5['arrs'][Targs, 8000:, :]\n",
    "data_train = data_train.reshape(Targs.shape[0] * 8000, 1600)\n",
    "\n",
    "# Additional validation sets for other G values\n",
    "data_validate_new = f5_new['arrs'][Targs, 8000:, :]\n",
    "data_validate_new2 = f5_new_2['arrs'][Targs, 8000:, :]\n",
    "data_validate_new3 = f5_new_3['arrs'][Targs_new, 8000:, :]\n",
    "data_validate_new4 = f5_new_4['arrs'][Targs, 8000:, :]\n",
    "\n",
    "labels_train = np.repeat(labels_tmp, 8000)\n",
    "labels_validate = np.repeat(labels_tmp, 2000)\n",
    "\n",
    "data_train = torch.tensor(data_train)\n",
    "labels_train = torch.tensor(labels_train, requires_grad=False)\n",
    "labels_validate = torch.tensor(labels_validate, requires_grad=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
